{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9phsvhzgEhK"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cesarlegendre/credit_scoring_7904_Q4_2024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Health insurance cost\n",
        "\n",
        "### Introduction\n",
        "\n",
        "This notebook aims to predict individual medical costs billed by health insurance based on several factors using LogisticRegression, KNeighborsClassifier,RandomForestClassifier, RandomForestClassifier, SVC (Support Vector Classifier), GradientBoostingClassifier. We will clean the data, feature engieniring, data split for crosss valitation, hyper parameter tunning and seletion of the models.\n"
      ],
      "metadata": {
        "id": "igfgvWbZiuZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "file = 'credit_scoring_7904_Q4_2024/data_sets/health_cost/insurance.csv'\n"
      ],
      "metadata": {
        "id": "ENTbAikwjap9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Data\n",
        "We load the dataset which contains information about age, sex, BMI, smoking habits, number of children, region, and medical charges."
      ],
      "metadata": {
        "id": "Rwnelmzhjl5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_csv(file)\n",
        "data.sample(4)\n"
      ],
      "metadata": {
        "id": "WAWCx1mxjjAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Understanding the Data\n",
        "\n",
        "##Column Descriptions:\n",
        "\n",
        "* **age**: Age of the primary beneficiary.\n",
        "* **sex**: Gender of the beneficiary.\n",
        "* **bmi**: Body Mass Index, a measure of body fat based on height and weight.\n",
        "* **children**: Number of dependents.\n",
        "* **smoker**: Whether the beneficiary is a smoker.\n",
        "* **region**: Region in the US where the beneficiary resides.\n",
        "* **charges**: Medical costs billed by the * health insurance (target variable).\n",
        "\n",
        "We inspect the structure of the dataset and calculate basic statistics."
      ],
      "metadata": {
        "id": "qcbV1RiWhOwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # This problem is transformed into a classification one (targer eng.)"
      ],
      "metadata": {
        "id": "sAqFn3ZGZ0sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot the distribution of the charges\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['charges'], bins=30, kde=True)\n",
        "plt.title('Distribution of Medical Charges')\n",
        "plt.xlabel('Medical Charges')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iOg8EVhAZ1zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data['Expensive Client'] = data['charges'] > 10000\n",
        "data = data.drop('charges', axis=1)\n"
      ],
      "metadata": {
        "id": "NeAc3lFxZ86y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "izcocgLcaM2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "## Encoding the 'sex' Variable\n",
        "The sex variable has two categories: 'female' and 'male'. We'll map these to numerical values.\n",
        "\n",
        "Checking Unique Values"
      ],
      "metadata": {
        "id": "Mlb9eCqObWyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check sex\n",
        "\n",
        "data['sex'].unique()\n"
      ],
      "metadata": {
        "id": "BDiaHYIUbTzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['sex_male'] = data['sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "data = data.drop('sex', axis=1)\n"
      ],
      "metadata": {
        "id": "x8x3ts-obj2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the 'smoker' Variable\n",
        "The smoker variable has two categories: 'yes' and 'no'.\n",
        "\n",
        "Checking Unique Values"
      ],
      "metadata": {
        "id": "f4GmXuvNb1GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['smoker'].unique()\n"
      ],
      "metadata": {
        "id": "WBMn8DjSb8Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['smoker_yes'] = data['smoker'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "data = data.drop('smoker', axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "44PhHLMJb_sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the 'region' Variable\n",
        "The region variable has four categories:\n",
        "\n",
        "* '**southwest**'\n",
        "* '**southeast**'\n",
        "* '**northwest**'\n",
        "* '**northeast**'\n",
        "\n",
        "We need to create dummy variables for these, dropping one category to avoid the dummy variable trap.\n",
        "\n",
        "Checking Unique Values"
      ],
      "metadata": {
        "id": "8TCVoPEJcL0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['region'].unique()\n"
      ],
      "metadata": {
        "id": "urPgPnuwcWWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regions = ['southwest', 'southeast', 'northwest']  # Excluding 'northeast'\n",
        "\n",
        "for region in regions:\n",
        "    column_name = 'region_' + region\n",
        "    data[column_name] = data['region'].apply(lambda x: 1 if x == region else 0)\n",
        "\n",
        "data = data.drop('region', axis=1)\n"
      ],
      "metadata": {
        "id": "eoC7lpjdcX7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting 'Expensive Client' to Numerical\n",
        "If the Expensive Client column is of boolean type, we'll convert it to integers."
      ],
      "metadata": {
        "id": "s3xqxx9OcqjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Expensive Client'].dtype"
      ],
      "metadata": {
        "id": "QogS6heAcrnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Expensive Client'] = data['Expensive Client'].astype(int)\n"
      ],
      "metadata": {
        "id": "KkRJwlLVctrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "vNr4Rif3cjfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking distribution of the numerical values\n",
        "\n",
        "As the values are correct, not normalization will be applied"
      ],
      "metadata": {
        "id": "LhHzOmQWdBkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Plotting histograms for bmi, age, and children and expensive client\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "sns.histplot(data['bmi'], bins=30, kde=True)\n",
        "plt.title('Distribution of BMI')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "sns.histplot(data['age'], bins=30, kde=True)\n",
        "plt.title('Distribution of Age')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "sns.histplot(data['children'], bins=30, kde=True)\n",
        "plt.title('Distribution of Children')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "sns.histplot(data['Expensive Client'], bins=30, kde=True)\n",
        "plt.title('Distribution of Expensive Client')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I8jmbz3mf4xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting histograms for bmi, age, and children\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(data['bmi'], bins=20)\n",
        "plt.title('Distribution of BMI')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.hist(data['age'], bins=20)\n",
        "plt.title('Distribution of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.hist(data['children'], bins=20)\n",
        "plt.title('Distribution of Children')\n",
        "plt.xlabel('Children')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qhheo8cAcFNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters tunning\n",
        "\n",
        "we'll train several classifiers to predict whether a client is expensive based on their features. The classifiers we'll use are:\n",
        "\n",
        "Logistic Regression\n",
        "\n",
        "*  K-Nearest Neighbors Classifier\n",
        "* Random Forest Classifier\n",
        "* Support Vector Classifier (SVC)\n",
        "* Gradient Boosting Classifie\n",
        "\n",
        "We'll use K-fold cross-validation and Grid Search to find the best hyperparameters for each model. Let's proceed step by step with explanations."
      ],
      "metadata": {
        "id": "dRgxQ_x6leja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "metadata": {
        "id": "ZYQYtF8qeY-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data\n",
        "We'll assume the data has been preprocessed as per the previous steps, and we have a DataFrame data with the following columns:\n",
        "\n",
        "* age\n",
        "* bmi\n",
        "* children\n",
        "* Expensive Client (target variable)\n",
        "* sex_male\n",
        "* smoker_yes\n",
        "* region_southwest\n",
        "* region_southeast\n",
        "* region_northwest\n",
        "\n",
        "### Splitting Features and Target Variable"
      ],
      "metadata": {
        "id": "3VlUL4xxecUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Expensive Client', axis=1)\n",
        "y = data['Expensive Client']\n"
      ],
      "metadata": {
        "id": "fqn71gnheopP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Data into Training and Test Sets\n",
        "We'll split the data into training and test sets to evaluate the final model performance after hyperparameter tuning."
      ],
      "metadata": {
        "id": "O8Us-1ntesKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Using a 80/20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "# Note: We use stratify=y to maintain the same class distribution in both training and test sets.\n"
      ],
      "metadata": {
        "id": "ponBoSCceZxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining K-Fold Cross-Validation Strategy\n",
        "We'll use Stratified K-Fold cross-validation to maintain class distribution during cross-validation."
      ],
      "metadata": {
        "id": "6Ol7yfeQe9Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "bSuj-Gp5e_n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Logistic Regression\n",
        "### Hyperparameter Grid\n",
        "For Logistic Regression, we'll tune the following hyperparameters:\n",
        "\n",
        "* C: Inverse of regularization strength\n",
        "* solver: Algorithm to use in the optimization problem"
      ],
      "metadata": {
        "id": "kYjrenDPfDwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "\n",
        "grid_search_lr = GridSearchCV(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    param_grid=param_grid_lr,\n",
        "    cv=kfold,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search_lr.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "DD33ZUplfApu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Hyperparameters for Logistic Regression:\")\n",
        "print(grid_search_lr.best_params_)"
      ],
      "metadata": {
        "id": "E7G7nOzkfqFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "YhZCmS72gT_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = grid_search_lr.best_estimator_\n",
        "y_pred_lr = best_lr.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report for Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "id": "nI4CKQwofwed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. K-Nearest Neighbors Classifier\n",
        "\n",
        "###  Hyperparameter Grid\n",
        "We'll tune the following hyperparameters:\n",
        "\n",
        "* n_neighbors: Number of neighbors to use\n",
        "* weights: Weight function used in prediction\n",
        "* metric: Distance metric"
      ],
      "metadata": {
        "id": "bKYWgvtygZQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "\n",
        "grid_search_knn = GridSearchCV(\n",
        "    estimator=KNeighborsClassifier(),\n",
        "    param_grid=param_grid_knn,\n",
        "    cv=kfold,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters for KNN:\")\n",
        "print(grid_search_knn.best_params_)\n"
      ],
      "metadata": {
        "id": "Tm71HE33gXeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating on Test Set\n"
      ],
      "metadata": {
        "id": "QZ3HtiZtgomb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_knn = grid_search_knn.best_estimator_\n",
        "y_pred_knn = best_knn.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report for KNN:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ],
      "metadata": {
        "id": "bePJ3-OhgnBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Random Forest Classifier\n",
        "\n",
        "### Hyperparameter Grid\n",
        "We'll tune the following hyperparameters:\n",
        "\n",
        "* n_estimators: Number of trees\n",
        "* max_depth: Maximum depth of the tree\n",
        "* min_samples_split: Minimum number of samples required to split\n",
        "* min_samples_leaf: Minimum number of samples required at a leaf node\n",
        "* max_features: Number of features to consider when looking for the best split\n",
        "python"
      ],
      "metadata": {
        "id": "7YqZ1-EnhCvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_grid_rf,\n",
        "    n_iter=50,  # Number of parameter settings that are sampled\n",
        "    cv=kfold,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search_rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "IAVX4BAog6zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Hyperparameters for Random Forest:\")\n",
        "print(random_search_rf.best_params_)\n"
      ],
      "metadata": {
        "id": "idq9hksChLMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating on Test Set\n"
      ],
      "metadata": {
        "id": "NzbmxyylhpVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf = random_search_rf.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report for Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "v9RybUBuhmc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  4. Support Vector Classifier (SVC)\n",
        "\n",
        "### Hyperparameter Grid\n",
        "We'll tune the following hyperparameters:\n",
        "\n",
        "* C: Regularization parameter\n",
        "* kernel: Specifies the kernel type\n",
        "\n"
      ],
      "metadata": {
        "id": "x4H1ZIzvhwy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_svc = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['rbf', 'sigmoid'],\n",
        "}\n"
      ],
      "metadata": {
        "id": "lyCk6b1uh--O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_svc = GridSearchCV(\n",
        "    estimator=SVC(),\n",
        "    param_grid=param_grid_svc,\n",
        "    cv=kfold,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "grid_search_svc.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "8p3TYE0Wh25u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Hyperparameters for SVC:\")\n",
        "print(grid_search_svc.best_params_)\n"
      ],
      "metadata": {
        "id": "FkFQ-9RLiDp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating on Test Set\n"
      ],
      "metadata": {
        "id": "LHgjNeBriMQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_svc = grid_search_svc.best_estimator_\n",
        "y_pred_svc = best_svc.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report for SVC:\")\n",
        "print(classification_report(y_test, y_pred_svc))\n"
      ],
      "metadata": {
        "id": "AbyTVm1tiLlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Gradient Boosting Classifier\n",
        "Hyperparameter Grid\n",
        "We'll tune the following hyperparameters:\n",
        "\n",
        "* n_estimators: Number of boosting stages\n",
        "* learning_rate: Learning rate shrinks the contribution of each tree\n",
        "* max_depth: Maximum depth of the individual regression estimators\n",
        "* min_samples_split: Minimum number of samples required to split\n",
        "* min_samples_leaf: Minimum number of samples required at a leaf node"
      ],
      "metadata": {
        "id": "yeanM98kh1Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "\n",
        "random_search_gb = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingClassifier(random_state=42),\n",
        "    param_distributions=param_grid_gb,\n",
        "    n_iter=50,\n",
        "    cv=kfold,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search_gb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "5B-LeTc-io4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Hyperparameters for Gradient Boosting:\")\n",
        "print(random_search_gb.best_params_)\n"
      ],
      "metadata": {
        "id": "S-4BddPjivBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on test set"
      ],
      "metadata": {
        "id": "cBsv_bxLi38o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_gb = random_search_gb.best_estimator_\n",
        "y_pred_gb = best_gb.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report for Gradient Boosting:\")\n",
        "print(classification_report(y_test, y_pred_gb))\n"
      ],
      "metadata": {
        "id": "l_BohYU0jGiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Model Performances\n",
        "Let's compile the accuracy scores of all models for comparison."
      ],
      "metadata": {
        "id": "Ty5c5ZW_j86L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': accuracy_score(y_test, y_pred_lr),\n",
        "    'K-Nearest Neighbors': accuracy_score(y_test, y_pred_knn),\n",
        "    'Random Forest': accuracy_score(y_test, y_pred_rf),\n",
        "    'Support Vector Classifier': accuracy_score(y_test, y_pred_svc),\n",
        "    'Gradient Boosting': accuracy_score(y_test, y_pred_gb)\n",
        "}\n",
        "\n",
        "print(\"\\nAccuracy Scores:\")\n",
        "for model_name, accuracy in models.items():\n",
        "    print(f\"{model_name}: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "5eiMw2v3j_ed"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
