{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifier Exercise with Digits Dataset\n",
        "\n",
        "This notebook will guide you through implementing a Random Forest classifier using Python's popular `scikit-learn` library. We will use the `load_digits` dataset, which contains images of handwritten digits, to demonstrate the capabilities of the Random Forest model.\n",
        "\n",
        "## Objectives\n",
        "- Understand how to build a Random Forest classifier.\n",
        "- Visualize sample images from the dataset.\n",
        "- Learn how to interpret the model's feature importance.\n",
        "- Apply model evaluation techniques to assess performance."
      ],
      "metadata": {
        "id": "uG4pmM3gntxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "FeCd9H6nnvLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load the Digits Dataset\n",
        "\n",
        "We will use the `load_digits` dataset from `scikit-learn`. The dataset contains images of digits (0-9), which are represented as 8x8 pixel matrices."
      ],
      "metadata": {
        "id": "JnfiYN66nvVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load digits dataset from sklearn\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Display dataset information\n",
        "print(f\"Number of samples: {len(digits.images)}\")\n",
        "print(f\"Image shape: {digits.images[0].shape}\")\n",
        "\n",
        "# Convert the dataset to a DataFrame for easier handling\n",
        "data = pd.DataFrame(data=digits.data, columns=[f'pixel_{i}' for i in range(digits.data.shape[1])])\n",
        "data['target'] = digits.target\n",
        "\n",
        "# Show the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "hmikwFSVnvcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 3: Visualize Sample Images\n",
        "\n",
        "To better understand the dataset, we will visualize a few sample images along with their corresponding labels."
      ],
      "metadata": {
        "id": "hcgueOShnvkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a few samples of the dataset\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 4))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(digits.images[i], cmap='gray')\n",
        "    ax.set_title(f\"Label: {digits.target[i]}\")\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"Sample Images from Digits Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BhAOBCrLnvrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Split the Data into Training and Test Sets\n",
        "\n",
        "We will split the dataset into training and testing sets using a 70/30 ratio.\n"
      ],
      "metadata": {
        "id": "23b9wudZnvyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) and target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% for training, 30% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "wlQmV5Dwnv39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Step 5: Train the Random Forest Model\n",
        "\n",
        "We will train a Random Forest classifier using the following important parameters:\n",
        "- **n_estimators**: Number of trees in the forest.\n",
        "- **max_depth**: Maximum depth of the trees to avoid overfitting.\n",
        "- **random_state**: Ensures reproducibility of the results.\n"
      ],
      "metadata": {
        "id": "aFiR-SJCnv96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize and train the Random Forest model\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "KI9wJhYMnwDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 6: Feature Importance\n",
        "\n",
        "One of the benefits of using a Random Forest model is the ability to analyze feature importance. In this dataset, each pixel is considered a feature."
      ],
      "metadata": {
        "id": "apbBrMpenwJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importance\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to visualize feature importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': [f'pixel_{i}' for i in range(X.shape[1])],\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False).head(10)  # Show top 10 most important pixels\n",
        "\n",
        "# Plotting feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Top 10 Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wz0aUghQnwOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Make Predictions and Evaluate the Model\n",
        "\n",
        "We will make predictions on the test set and evaluate the model’s performance using metrics like accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "NcXYqrEGnwUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=digits.target_names, yticklabels=digits.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5z31LC1Eox6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation of the Results\n",
        "\n",
        "- **Feature Importance**: The feature importance plot shows which pixels have the highest contribution to the model's classification decision. This allows us to understand which areas of the digit images are most critical.\n",
        "- **Confusion Matrix**: The confusion matrix gives an overview of the model's predictions versus the actual classes, helping identify any misclassification patterns.\n",
        "- **Accuracy and Classification Report**: The accuracy score and classification report provide insight into the model's precision, recall, and F1-score, indicating how well the model is performing overall.\n",
        "\n",
        "## Key Points\n",
        "\n",
        "- **n_estimators**: Defines the number of trees in the Random Forest. A higher number typically results in better performance but increases computational cost.\n",
        "- **max_depth**: Limiting the depth of the trees helps in controlling overfitting and ensures the model generalizes better to unseen data.\n",
        "- **Random Forest**: It’s an ensemble model that helps in improving performance and reducing overfitting compared to a single decision tree.\n",
        "\n",
        "### Final Thoughts\n",
        "\n",
        "Random Forest is a powerful and flexible algorithm for classification tasks. It works well with the `digits` dataset, which has high-dimensional features (i.e., pixels). By analyzing feature importance, we can understand which features contribute most to the decision-making process of the model.\n",
        "\n",
        "Feel free to experiment with other hyperparameters like **min_samples_split** or **max_features** to see how they impact the model's performance.\n"
      ],
      "metadata": {
        "id": "7bFfA7XooyDV"
      }
    }
  ]
}
